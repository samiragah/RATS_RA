{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6e9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Performance Tests ===\n",
      "Waiting 5 seconds for servers to stabilize...\n",
      "\n",
      "==================================================\n",
      "=== RATS Architecture Test ===\n",
      " RATS connection test: OK\n",
      " RATS Performance (n=30):\n",
      "   - Successful: 30/30\n",
      "   - Failed: 0\n",
      "   - Avg Latency: 10521.31 ms\n",
      "   - Min Latency: 10270.04 ms\n",
      "   - Max Latency: 10738.17 ms\n",
      "   - Throughput: 30.00 req/sec\n",
      "\n",
      "==================================================\n",
      "=== Monolithic Architecture Test ===\n",
      " Monolithic connection test: OK\n",
      " Monolithic Performance (n=30):\n",
      "   - Successful: 30/30\n",
      "   - Failed: 0\n",
      "   - Avg Latency: 302.86 ms\n",
      "   - Min Latency: 11.58 ms\n",
      "   - Max Latency: 351.22 ms\n",
      "   - Throughput: 30.00 req/sec\n",
      "\n",
      "==================================================\n",
      "=== Final Results ===\n",
      "  architecture   avg_latency   min_latency   max_latency  throughput  \\\n",
      "0         RATS  10521.305895  10270.043850  10738.174438          30   \n",
      "1   Monolithic    302.858170     11.582136    351.217985          30   \n",
      "\n",
      "   successful  failed  total  \n",
      "0          30       0     30  \n",
      "1          30       0     30  \n",
      "\n",
      " Performance Comparison:\n",
      "   - Latency Improvement: -3374.0%\n",
      "   - Throughput Improvement: +0.0%\n",
      " Results saved to performance_results.csv\n"
     ]
    }
   ],
   "source": [
    "# end-user\n",
    "\n",
    "import asyncio\n",
    "import httpx\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "async def send_request(client, url, data):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = await client.post(url, json=data, timeout=60.0)  # افزایش timeout\n",
    "        end_time = time.time()\n",
    "        latency = (end_time - start_time) * 1000  # ms\n",
    "        \n",
    "        # بررسی اینکه پاسخ معتبر است\n",
    "        response_data = response.json()\n",
    "        if \"error\" in response_data:\n",
    "            return {\"latency\": latency, \"status\": \"error\", \"error\": response_data[\"error\"]}\n",
    "            \n",
    "        return {\"latency\": latency, \"status\": \"success\", \"response\": response_data}\n",
    "        \n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        latency = (end_time - start_time) * 1000\n",
    "        return {\"latency\": latency, \"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "async def benchmark_system(url, system_name, n_requests=30):  # کاهش تعداد درخواست‌ها برای تست اولیه\n",
    "    data = {\"symbol\": \"AAPL\", \"interval\": \"1h\"}\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        # تست اولیه برای اطمینان از سلامت connection\n",
    "        try:\n",
    "            test_response = await client.post(url, json=data, timeout=10.0)\n",
    "            print(f\" {system_name} connection test: OK\")\n",
    "        except Exception as e:\n",
    "            print(f\" {system_name} connection test failed: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # اجرای درخواستهای اصلی\n",
    "        tasks = [send_request(client, url, data) for _ in range(n_requests)]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        successful = [r for r in results if r[\"status\"] == \"success\"]\n",
    "        failed = [r for r in results if r[\"status\"] == \"error\"]\n",
    "        \n",
    "        if len(successful) > 0:\n",
    "            latencies = [r[\"latency\"] for r in successful]\n",
    "            avg_latency = sum(latencies) / len(latencies)\n",
    "            max_latency = max(latencies)\n",
    "            min_latency = min(latencies)\n",
    "            \n",
    "            # محاسبه throughput بر اساس کل زمان تست\n",
    "            first_request_time = min([r.get('start_time', 0) for r in successful if 'start_time' in r], default=0)\n",
    "            last_request_time = max([r.get('end_time', 0) for r in successful if 'end_time' in r], default=0)\n",
    "            \n",
    "            if last_request_time > first_request_time:\n",
    "                total_time = last_request_time - first_request_time\n",
    "                throughput = len(successful) / total_time\n",
    "            else:\n",
    "                throughput = len(successful)  # fallback\n",
    "            \n",
    "            print(f\" {system_name} Performance (n={n_requests}):\")\n",
    "            print(f\"   - Successful: {len(successful)}/{n_requests}\")\n",
    "            print(f\"   - Failed: {len(failed)}\")\n",
    "            print(f\"   - Avg Latency: {avg_latency:.2f} ms\")\n",
    "            print(f\"   - Min Latency: {min_latency:.2f} ms\")\n",
    "            print(f\"   - Max Latency: {max_latency:.2f} ms\")\n",
    "            print(f\"   - Throughput: {throughput:.2f} req/sec\")\n",
    "            \n",
    "            if failed:\n",
    "                print(f\"   - Errors: {[f['error'] for f in failed[:3]]}\")  # نمایش 3 خطای اول\n",
    "            \n",
    "            return {\n",
    "                \"architecture\": system_name,\n",
    "                \"avg_latency\": avg_latency,\n",
    "                \"min_latency\": min_latency,\n",
    "                \"max_latency\": max_latency,\n",
    "                \"throughput\": throughput,\n",
    "                \"successful\": len(successful),\n",
    "                \"failed\": len(failed),\n",
    "                \"total\": n_requests\n",
    "            }\n",
    "        else:\n",
    "            print(f\" No successful requests for {system_name}\")\n",
    "            print(f\"   Errors: {[f['error'] for f in failed[:5]]}\")  # نمایش 5 خطای اول\n",
    "            return None\n",
    "\n",
    "# اجرای تستها\n",
    "print(\"=== Starting Performance Tests ===\")\n",
    "print(\"Waiting 5 seconds for servers to stabilize...\")\n",
    "await asyncio.sleep(5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== RATS Architecture Test ===\")\n",
    "rats_results = await benchmark_system(\n",
    "    \"http://localhost:8000/request-signal\", \n",
    "    \"RATS\", \n",
    "    n_requests=30  # تعداد کمتر برای تست اولیه\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Monolithic Architecture Test ===\")\n",
    "mono_results = await benchmark_system(\n",
    "    \"http://localhost:8002/request-signal-mono\", \n",
    "    \"Monolithic\",\n",
    "    n_requests=30\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Final Results ===\")\n",
    "\n",
    "if rats_results and mono_results:\n",
    "    # ایجاد DataFrame برای نتایج\n",
    "    results_df = pd.DataFrame([rats_results, mono_results])\n",
    "    \n",
    "    # نمایش نتایج\n",
    "    print(results_df[['architecture', 'avg_latency', 'min_latency', 'max_latency', \n",
    "                     'throughput', 'successful', 'failed', 'total']])\n",
    "    \n",
    "    # محاسبه بهبود performance\n",
    "    latency_improvement = ((mono_results['avg_latency'] - rats_results['avg_latency']) / mono_results['avg_latency']) * 100\n",
    "    throughput_improvement = ((rats_results['throughput'] - mono_results['throughput']) / mono_results['throughput']) * 100\n",
    "    \n",
    "    print(f\"\\n Performance Comparison:\")\n",
    "    print(f\"   - Latency Improvement: {latency_improvement:+.1f}%\")\n",
    "    print(f\"   - Throughput Improvement: {throughput_improvement:+.1f}%\")\n",
    "    \n",
    "    # ذخیره نتایج\n",
    "    results_df.to_csv(\"performance_results.csv\", index=False)\n",
    "    print(\" Results saved to performance_results.csv\")\n",
    "    \n",
    "elif rats_results:\n",
    "    print(\" Only RATS test completed successfully\")\n",
    "    print(pd.DataFrame([rats_results]))\n",
    "elif mono_results:\n",
    "    print(\" Only Monolithic test completed successfully\")  \n",
    "    print(pd.DataFrame([mono_results]))\n",
    "else:\n",
    "    print(\" Both tests failed. Please check server logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28635b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
